{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a084d0fc"
      },
      "source": [
        "# Federated Learning Model Poisoning Attack Simulation"
      ],
      "id": "a084d0fc"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "c41d4476"
      },
      "outputs": [],
      "source": [
        "!pip install -q flwr[simulation] torch torchvision matplotlib\n",
        "\n",
        "from collections import OrderedDict\n",
        "from typing import List, Tuple, Optional, Callable\n",
        "from matplotlib import pyplot as plt\n",
        "import certifi\n",
        "import ssl\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split, Subset, Dataset\n",
        "from torchvision.datasets import CIFAR10\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "import os\n",
        "\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" # fixed something with matplotlib killing the kernel\n",
        "ssl._create_default_https_context = ssl._create_unverified_context  # fixed something with the ssl certificate of the dataset\n",
        "DEVICE = torch.device(\"cpu\")  # \"cpu\" -> train in cpu | \"cuda\" -> train in gpu"
      ],
      "id": "c41d4476"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "225fa440"
      },
      "outputs": [],
      "source": [
        "from logging import WARNING # we need those imports to implement the strategy class\n",
        "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "from flwr.common import (\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    MetricsAggregationFn,\n",
        "    NDArrays,\n",
        "    Parameters,\n",
        "    Scalar,\n",
        "    ndarrays_to_parameters,\n",
        "    parameters_to_ndarrays,\n",
        ")\n",
        "from flwr.common.logger import log\n",
        "from flwr.server.client_manager import ClientManager\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "\n",
        "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg, aggregate_krum\n",
        "from flwr.server.strategy.strategy import Strategy"
      ],
      "id": "225fa440"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "e7a839c4"
      },
      "outputs": [],
      "source": [
        "CLASSES = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\") # classes of the example dataset\n",
        "\n",
        "NUM_CLIENTS = 10 # this is the number of devices participating in the federated learning\n",
        "\n",
        "BATCH_SIZE = 32 # this is the size of a mini-batch for the training of a CNN using SGD"
      ],
      "id": "e7a839c4"
    },
    {
      "cell_type": "code",
      "source": [
        "class MaliciousDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.modifiedData = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.modifiedData)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.modifiedData[idx]\n",
        "\n",
        "    def __insertitem___(self, item):\n",
        "        self.modifiedData.append(item)"
      ],
      "metadata": {
        "id": "BOHBuxFwYmKG"
      },
      "id": "BOHBuxFwYmKG",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe1dcda9",
        "outputId": "1fa319f0-ab7c-40df-e9c1-6f433abdcd36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "def load_datasets(): # download and transform cifar-10\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
        "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
        "\n",
        "    # split training set into 10 partitions to simulate the individual dataset\n",
        "    partition_size = len(trainset) // NUM_CLIENTS\n",
        "    lengths = [partition_size] * NUM_CLIENTS\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    dsidx = 0\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10% validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "        #############################################################################\n",
        "        ######################----SIMULATE THE DATA ATTACK----#######################\n",
        "        #############################################################################\n",
        "        if dsidx < int(NUM_CLIENTS*0.3):\n",
        "            datasetIndices = ds_train.indices\n",
        "            clientDataset = ds_train.dataset\n",
        "            poisonedDataset = MaliciousDataset()\n",
        "            for index in range(len(datasetIndices)):\n",
        "                poisonedDataset.__insertitem___((clientDataset[datasetIndices[index]][0], random.randint(0, 9)))\n",
        "            ds_train = Subset(poisonedDataset, [i for i in range(poisonedDataset.__len__())])\n",
        "        #############################################################################\n",
        "        #############################################################################\n",
        "        #############################################################################\n",
        "\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
        "        dsidx = dsidx + 1\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets() # load the datasets"
      ],
      "id": "fe1dcda9"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "876b7b4b"
      },
      "outputs": [],
      "source": [
        "class LeNet5(nn.Module):\n",
        "    def __init__(self, num_classes, grayscale=False):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        self.grayscale = grayscale\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        if self.grayscale:\n",
        "            in_channels = 1\n",
        "        else:\n",
        "            in_channels = 3\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(in_channels, 6*in_channels, kernel_size=5),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(6*in_channels, 16*in_channels, kernel_size=5),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(16*5*5*in_channels, 120*in_channels),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(120*in_channels, 84*in_channels),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(84*in_channels, num_classes),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "        return logits, probas"
      ],
      "id": "876b7b4b"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "2d8d6556"
      },
      "outputs": [],
      "source": [
        "def train(net, trainloader, epochs: int, verbose=False): # we need a train and a test function that our clients will be using\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad() # reset the gradients\n",
        "            outputs, probas = net(images) # do the forward pass\n",
        "            loss = criterion(outputs, labels) # calculate the loss function\n",
        "            loss.backward() # calculate the gradients of the loss function\n",
        "            optimizer.step() # do one stochastic gradient descent step\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "\n",
        "        if verbose: # log information\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs, probas = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(probas.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "id": "2d8d6556"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "88a324a2"
      },
      "outputs": [],
      "source": [
        "def get_parameters(net) -> List[np.ndarray]: # we need these two function because this way flower knows how\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()] # to serialize/deserialize data\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)"
      ],
      "id": "88a324a2"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "9a3bd9fc"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient): # here we define the FlowerClient. We have to implement only the following 3 methods\n",
        "    def __init__(self, net, trainloader, valloader): # of course we can customize these methods as we like\n",
        "        self.net = net                            # we can add extra member variables as well\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
      ],
      "id": "9a3bd9fc"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "0acd8c0d"
      },
      "outputs": [],
      "source": [
        "class BenignFlowerClient(FlowerClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        super().__init__(net, trainloader, valloader)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        #print(\"Benign Client Got Selected\", flush=True)\n",
        "        parameters, num_examples, _ = super().fit(parameters, config)\n",
        "        return parameters, num_examples, {\"intention\": \"BENIGN\"}\n",
        "\n",
        "class MaliciousFlowerClient(FlowerClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        super().__init__(net, trainloader, valloader)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        #print(\"Malicious Client Got Selected\", flush=True)\n",
        "        parameters, num_examples, _ = super().fit(parameters, config)\n",
        "        return parameters, num_examples, {\"intention\": \"MALICIOUS\"}"
      ],
      "id": "0acd8c0d"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "53436036"
      },
      "outputs": [],
      "source": [
        "def client_fn(cid: str) -> FlowerClient: # this is a factory function (factory desing pattern)\n",
        "    net = LeNet5(10).to(DEVICE) # flower calls this function to create FlowerClients on demand (this way it uses less memory)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "\n",
        "    if int(cid) <= NUM_CLIENTS * 0.2:    # 20 - 80 --> malicious - benign\n",
        "        return MaliciousFlowerClient(net, trainloader, valloader)\n",
        "    else:\n",
        "        return BenignFlowerClient(net, trainloader, valloader)"
      ],
      "id": "53436036"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "70f89874"
      },
      "outputs": [],
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics: # we pass this function as an argument to the Strategy\n",
        "    # calculate accuracy\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # return it as a dictionary\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "id": "70f89874"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "0a7aa153"
      },
      "outputs": [],
      "source": [
        "class AttackSimulationStrategy(fl.server.strategy.FedAvg): # we inherit from FedAvg strategy and change only what we need\n",
        "    def __init__(self, *, fraction_fit: float = 1.0, fraction_evaluate: float = 1.0, min_fit_clients: int = 2,\n",
        "        min_evaluate_clients: int = 2, min_available_clients: int = 2, num_malicious_clients: int = 2,\n",
        "        num_clients_to_keep: int = 0, evaluate_fn: Optional[Callable[[int, NDArrays, Dict[str, Scalar]],\n",
        "        Optional[Tuple[float, Dict[str, Scalar]]],]] = None, on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None, accept_failures: bool = True,\n",
        "        initial_parameters: Optional[Parameters] = None, fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        perturbationVector: str, adversaryKnowledge: str\n",
        "    ) -> None:\n",
        "        super().__init__(\n",
        "            fraction_fit=fraction_fit, fraction_evaluate=fraction_evaluate, min_fit_clients=min_fit_clients,\n",
        "            min_evaluate_clients=min_evaluate_clients, min_available_clients=min_available_clients, evaluate_fn=evaluate_fn,\n",
        "            on_fit_config_fn=on_fit_config_fn, on_evaluate_config_fn=on_evaluate_config_fn, accept_failures=accept_failures,\n",
        "            initial_parameters=initial_parameters, fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n",
        "            evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n",
        "        )\n",
        "        self.num_malicious_clients = num_malicious_clients\n",
        "        self.num_clients_to_keep = num_clients_to_keep\n",
        "        self.perturbationVector = perturbationVector\n",
        "        self.adversaryKnowledge = adversaryKnowledge\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        rep = f\"AttackSimulationStrategy(accept_failures={self.accept_failures})\"\n",
        "        return rep\n",
        "\n",
        "    def aggregate_fit(self, server_round: int, results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "\n",
        "        if not results: # boilerplate code to handle exceptions\n",
        "            return None, {}\n",
        "        if not self.accept_failures and failures:\n",
        "            return None, {}\n",
        "\n",
        "        # convert results\n",
        "        total_weights_results = [(parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples) for _, fit_res in results]\n",
        "\n",
        "        # calculate AGR\n",
        "        parameters_aggregated = ndarrays_to_parameters(aggregate_krum( # this thing here is for krum-AGR\n",
        "            total_weights_results, self.num_malicious_clients, self.num_clients_to_keep))\n",
        "\n",
        "        # boilerplate code if aggregation metrics are provided\n",
        "        metrics_aggregated = {}\n",
        "        if self.fit_metrics_aggregation_fn:\n",
        "            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
        "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
        "        elif server_round == 1:  # Only log this warning once\n",
        "            log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
        "\n",
        "        return parameters_aggregated, metrics_aggregated\n",
        "\n"
      ],
      "id": "0a7aa153"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "1befdde0",
        "outputId": "ac22eb4a-e828-49de-fb61-50ebf0a00b4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-10-17 19:33:14,286 | app.py:175 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "2023-10-17 19:33:21,181\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2023-10-17 19:33:26,072 | app.py:210 | Flower VCE: Ray initialized with resources: {'object_store_memory': 3916605849.0, 'memory': 7833211700.0, 'CPU': 2.0, 'node:__internal_head__': 1.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'object_store_memory': 3916605849.0, 'memory': 7833211700.0, 'CPU': 2.0, 'node:__internal_head__': 1.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0}\n",
            "INFO flwr 2023-10-17 19:33:26,076 | app.py:218 | No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO flwr 2023-10-17 19:33:26,098 | app.py:224 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO flwr 2023-10-17 19:33:26,168 | app.py:270 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO flwr 2023-10-17 19:33:26,171 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-10-17 19:33:26,177 | server.py:276 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=12016)\u001b[0m 2023-10-17 19:33:35.318528: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO flwr 2023-10-17 19:33:41,958 | server.py:280 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-10-17 19:33:41,963 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-10-17 19:33:41,966 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-10-17 19:33:41,968 | server.py:222 | fit_round 1: strategy sampled 8 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 8 clients (out of 10)\n",
            "DEBUG flwr 2023-10-17 19:34:53,998 | server.py:236 | fit_round 1 received 8 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 8 results and 0 failures\n",
            "WARNING flwr 2023-10-17 19:34:54,102 | <ipython-input-69-056b69faa33b>:48 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-10-17 19:34:54,106 | server.py:173 | evaluate_round 1: strategy sampled 8 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 8 clients (out of 10)\n",
            "DEBUG flwr 2023-10-17 19:35:30,582 | server.py:187 | evaluate_round 1 received 8 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 8 results and 0 failures\n",
            "DEBUG flwr 2023-10-17 19:35:30,587 | server.py:222 | fit_round 2: strategy sampled 8 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 8 clients (out of 10)\n",
            "DEBUG flwr 2023-10-17 19:36:43,237 | server.py:236 | fit_round 2 received 8 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 8 results and 0 failures\n",
            "DEBUG flwr 2023-10-17 19:36:43,347 | server.py:173 | evaluate_round 2: strategy sampled 8 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 8 clients (out of 10)\n",
            "DEBUG flwr 2023-10-17 19:37:21,330 | server.py:187 | evaluate_round 2 received 8 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 8 results and 0 failures\n",
            "DEBUG flwr 2023-10-17 19:37:21,367 | server.py:222 | fit_round 3: strategy sampled 8 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 8 clients (out of 10)\n",
            "DEBUG flwr 2023-10-17 19:38:29,882 | server.py:236 | fit_round 3 received 8 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 8 results and 0 failures\n",
            "DEBUG flwr 2023-10-17 19:38:29,975 | server.py:173 | evaluate_round 3: strategy sampled 8 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 8 clients (out of 10)\n",
            "DEBUG flwr 2023-10-17 19:39:07,963 | server.py:187 | evaluate_round 3 received 8 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 8 results and 0 failures\n",
            "DEBUG flwr 2023-10-17 19:39:07,972 | server.py:222 | fit_round 4: strategy sampled 8 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 8 clients (out of 10)\n",
            "DEBUG flwr 2023-10-17 19:40:19,229 | server.py:236 | fit_round 4 received 8 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 8 results and 0 failures\n",
            "DEBUG flwr 2023-10-17 19:40:19,324 | server.py:173 | evaluate_round 4: strategy sampled 8 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 8 clients (out of 10)\n",
            "DEBUG flwr 2023-10-17 19:40:55,231 | server.py:187 | evaluate_round 4 received 8 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 8 results and 0 failures\n",
            "DEBUG flwr 2023-10-17 19:40:55,234 | server.py:222 | fit_round 5: strategy sampled 8 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 8 clients (out of 10)\n",
            "DEBUG flwr 2023-10-17 19:42:07,760 | server.py:236 | fit_round 5 received 8 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 8 results and 0 failures\n",
            "DEBUG flwr 2023-10-17 19:42:07,859 | server.py:173 | evaluate_round 5: strategy sampled 8 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 8 clients (out of 10)\n",
            "DEBUG flwr 2023-10-17 19:42:43,993 | server.py:187 | evaluate_round 5 received 8 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 8 results and 0 failures\n",
            "INFO flwr 2023-10-17 19:42:44,039 | server.py:153 | FL finished in 542.0704207569997\n",
            "INFO:flwr:FL finished in 542.0704207569997\n",
            "INFO flwr 2023-10-17 19:42:44,047 | app.py:225 | app_fit: losses_distributed [(1, 0.07381261092424393), (2, 0.05530920425057411), (3, 0.05014918866753578), (4, 0.049052857935428615), (5, 0.04509883189201355)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.07381261092424393), (2, 0.05530920425057411), (3, 0.05014918866753578), (4, 0.049052857935428615), (5, 0.04509883189201355)]\n",
            "INFO flwr 2023-10-17 19:42:44,051 | app.py:226 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-10-17 19:42:44,054 | app.py:227 | app_fit: metrics_distributed {'accuracy': [(1, 0.09774999999999999), (2, 0.38125), (3, 0.426), (4, 0.45524999999999993), (5, 0.48575)]}\n",
            "INFO:flwr:app_fit: metrics_distributed {'accuracy': [(1, 0.09774999999999999), (2, 0.38125), (3, 0.426), (4, 0.45524999999999993), (5, 0.48575)]}\n",
            "INFO flwr 2023-10-17 19:42:44,056 | app.py:228 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-10-17 19:42:44,058 | app.py:229 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.07381261092424393\n",
              "\tround 2: 0.05530920425057411\n",
              "\tround 3: 0.05014918866753578\n",
              "\tround 4: 0.049052857935428615\n",
              "\tround 5: 0.04509883189201355\n",
              "History (metrics, distributed, evaluate):\n",
              "{'accuracy': [(1, 0.09774999999999999), (2, 0.38125), (3, 0.426), (4, 0.45524999999999993), (5, 0.48575)]}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "# create a strategy\n",
        "strategy = AttackSimulationStrategy(fraction_fit=0.8, fraction_evaluate=0.8, min_fit_clients=5,\n",
        "    min_evaluate_clients=5, min_available_clients=10, perturbationVector=\"InverseStd\", adversaryKnowledge=\"agr-only\",\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,) # <-- pass the metric aggregation function. This function will be called\n",
        "                                                       # in every federated learning round for evaluation (it aggregates the\n",
        "                                                       # client-side evaluation metrics in the server)\n",
        "\n",
        "# start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn, # out factory function\n",
        "    num_clients=NUM_CLIENTS, # number of clients\n",
        "    config=fl.server.ServerConfig(num_rounds=5), # number of federated learning rounds\n",
        "    strategy=strategy, # our attack simulation strategy\n",
        "    client_resources=None,\n",
        ")"
      ],
      "id": "1befdde0"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}