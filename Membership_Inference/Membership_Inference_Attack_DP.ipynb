{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a084d0fc",
      "metadata": {
        "id": "a084d0fc"
      },
      "source": [
        "# Federated Learning Model Poisoning Attack Simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c41d4476",
      "metadata": {
        "id": "c41d4476"
      },
      "outputs": [],
      "source": [
        "!pip install -q flwr[simulation] torch torchvision matplotlib opacus\n",
        "\n",
        "from collections import OrderedDict\n",
        "from typing import List, Tuple, Optional, Callable, Dict\n",
        "from matplotlib import pyplot as plt\n",
        "import certifi\n",
        "import ssl\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split, Dataset, Subset\n",
        "from torchvision.datasets import CIFAR10\n",
        "import flwr as fl\n",
        "from flwr.common import Parameters, Scalar, FitRes, Metrics, ReconnectIns\n",
        "import os\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.utils.uniform_sampler import UniformWithReplacementSampler\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" # fixed something with matplotlib killing the kernel\n",
        "ssl._create_default_https_context = ssl._create_unverified_context  # fixed something with the ssl certificate of the dataset\n",
        "DEVICE = torch.device(\"cpu\")  # \"cpu\" -> train in cpu | \"cuda\" -> train in gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "225fa440",
      "metadata": {
        "id": "225fa440"
      },
      "outputs": [],
      "source": [
        "from logging import WARNING # we need those imports to implement the strategy class\n",
        "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "from flwr.common import (\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    MetricsAggregationFn,\n",
        "    NDArrays,\n",
        "    Parameters,\n",
        "    Scalar,\n",
        "    ndarrays_to_parameters,\n",
        "    parameters_to_ndarrays,\n",
        ")\n",
        "from flwr.common.logger import log\n",
        "from flwr.server.client_manager import ClientManager\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "\n",
        "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg, aggregate_krum\n",
        "from flwr.server.strategy.strategy import Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e7a839c4",
      "metadata": {
        "id": "e7a839c4"
      },
      "outputs": [],
      "source": [
        "CLASSES = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\") # classes of the example dataset\n",
        "\n",
        "NUM_CLIENTS = 10 # this is the number of devices participating in the federated learning\n",
        "\n",
        "BATCH_SIZE = 32 # this is the size of a mini-batch for the training of a CNN using SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5pk7sbSz5On1",
      "metadata": {
        "id": "5pk7sbSz5On1"
      },
      "outputs": [],
      "source": [
        "histories = [None for _ in range(4)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fe1dcda9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe1dcda9",
        "outputId": "0300ae38-58c2-4133-dd17-7b6c2a98728c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 105412006.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./dataset/cifar-10-python.tar.gz to ./dataset\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "def load_datasets(): # download and transform cifar-10\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
        "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
        "\n",
        "    # split training set into 10 partitions to simulate the individual dataset\n",
        "    partition_size = len(trainset) // NUM_CLIENTS\n",
        "    lengths = [partition_size] * NUM_CLIENTS\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    shadowloaders = []\n",
        "    ctr = 1\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10% validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
        "        ctr = ctr + 1\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    return trainloaders, valloaders, testloader, shadowloaders\n",
        "\n",
        "trainloaders, valloaders, testloader, shadowloaders = load_datasets() # load the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "MjU0RegAttUm",
      "metadata": {
        "id": "MjU0RegAttUm"
      },
      "outputs": [],
      "source": [
        "class AttackMLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64,out_classes=2):\n",
        "        super(AttackMLP, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_size, out_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        out = self.classifier(x)\n",
        "        probas = F.softmax(out, dim=1)\n",
        "        return out, probas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "876b7b4b",
      "metadata": {
        "id": "876b7b4b"
      },
      "outputs": [],
      "source": [
        "class LeNet5(nn.Module):\n",
        "    def __init__(self, num_classes, grayscale=False):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        self.grayscale = grayscale\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        if self.grayscale:\n",
        "            in_channels = 1\n",
        "        else:\n",
        "            in_channels = 3\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(in_channels, 6*in_channels, kernel_size=5),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(6*in_channels, 16*in_channels, kernel_size=5),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(16*5*5*in_channels, 120*in_channels),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(120*in_channels, 84*in_channels),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(84*in_channels, num_classes),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "        return logits, probas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "wC26FunQ5Z3s",
      "metadata": {
        "id": "wC26FunQ5Z3s"
      },
      "outputs": [],
      "source": [
        "def get_target_delta(data_size: int) -> float: # this is the δ for the (ε, δ) differential privacy\n",
        "    den = 1\n",
        "    while data_size // den >= 1:\n",
        "        den *= 10\n",
        "    return 1 / den"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2d8d6556",
      "metadata": {
        "id": "2d8d6556"
      },
      "outputs": [],
      "source": [
        "def train(net, trainloader, epochs: int, nm, mgn, history, verbose=False, repeat=True): # we need a train and a test function that our clients will be using\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    delta = get_target_delta(len(trainloader.dataset)) # dp δ\n",
        "\n",
        "    if repeat == True:\n",
        "      privacy_engine = PrivacyEngine()\n",
        "      net, optimizer, trainloader = privacy_engine.make_private(\n",
        "          module=net,\n",
        "          optimizer=optimizer, # here we attach the optimizer with the DP engine so that in every stochastic gradient descent step it adds noise + gradient clipping + etc!\n",
        "          data_loader=trainloader,\n",
        "          noise_multiplier=nm,\n",
        "          max_grad_norm=mgn,\n",
        "      )\n",
        "\n",
        "    if history is not None:\n",
        "        privacy_engine.accountant.history = history\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        correct, total, epoch_loss, ctr = 0, 0, 0.0, 0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs, probas = net(images) # do the forward pass\n",
        "            loss = criterion(outputs, labels) # calculate the loss function\n",
        "            loss.backward() # calculate the gradients of the loss function\n",
        "\n",
        "            optimizer.step()  # the optimizer is now a dp-optimizer and this will be a real step or a virtual step depending on the dp state!\n",
        "\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "            ctr = ctr + 1\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "\n",
        "        if verbose: # log information\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "    epsilon = privacy_engine.accountant.get_epsilon(delta=delta)\n",
        "    history = privacy_engine.accountant.history\n",
        "    return epsilon, history\n",
        "\n",
        "def trainV2(net, trainloader, epochs: int, verbose=False): # we need a train and a test function that our clients will be using\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad() # reset the gradients\n",
        "            outputs, _ = net(images) # do the forward pass\n",
        "            loss = criterion(outputs, labels) # calculate the loss function\n",
        "            loss.backward() # calculate the gradients of the loss function\n",
        "            optimizer.step() # do one stochastic gradient descent step\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "\n",
        "        if verbose: # log information\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "def test(net, testloader):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs, probas = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(probas.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "88a324a2",
      "metadata": {
        "id": "88a324a2"
      },
      "outputs": [],
      "source": [
        "def get_parameters(net) -> List[np.ndarray]: # we need these two function because this way flower knows how\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()] # to serialize/deserialize data\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9a3bd9fc",
      "metadata": {
        "id": "9a3bd9fc"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient): # here we define the FlowerClient. We have to implement only the following 3 methods\n",
        "    def __init__(self, net, trainloader, valloader, eps, nm, mgn, history, cid): # of course we can customize these methods as we like\n",
        "        self.net = net                            # we can add extra member variables as well\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.eps = eps\n",
        "        self.nm = nm\n",
        "        self.mgn = mgn\n",
        "        self.history = history\n",
        "        self.parameters = None\n",
        "        self.cid = cid\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        self.parameters = get_parameters(self.net) # store previous parameters in case we have to discard the new ones because the epsilon value is not satisfied!\n",
        "        epsilon, history = train(self.net, self.trainloader, epochs=1, mgn=self.mgn, nm=self.nm, history= self.history)\n",
        "\n",
        "        accept = True # check if target epsilon value is respected\n",
        "        if epsilon > self.eps + 0.3:\n",
        "            accept = False # refuse client's new parameters\n",
        "            print(f\"Epsilon over target value ({self.eps}), disconnecting client.\")\n",
        "            set_parameters(self.net, self.parameters)\n",
        "        metrics = {\n",
        "            \"epsilon\": epsilon,\n",
        "            \"accept\": accept,\n",
        "            \"history\": history\n",
        "        }\n",
        "        return get_parameters(self.net), len(self.trainloader), metrics\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0acd8c0d",
      "metadata": {
        "id": "0acd8c0d"
      },
      "outputs": [],
      "source": [
        "class BenignFlowerClient(FlowerClient):\n",
        "    def __init__(self, net, trainloader, valloader, eps, nm, mgn, history, cid):\n",
        "        super().__init__(net, trainloader, valloader, eps, nm, mgn, history, cid)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        #print(\"Benign Client Got Selected\", flush=True)\n",
        "        parameters, num_examples, metrics = super().fit(parameters, config)\n",
        "        metrics[\"intention\"] = \"BENIGN\" # just add that the client is benign\n",
        "        return parameters, num_examples, metrics\n",
        "\n",
        "class MaliciousFlowerClient(FlowerClient):\n",
        "    def __init__(self, net, trainloader, valloader, eps, nm, mgn, history, cid):\n",
        "        super().__init__(net, trainloader, valloader, eps, nm, mgn, history, cid)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        #print(\"Malicious Client Got Selected\", flush=True)\n",
        "        parameters, num_examples, metrics = super().fit(parameters, config)\n",
        "        metrics[\"intention\"] = \"MALICIOUS\" # just add that the client is malicious\n",
        "        return parameters, num_examples, metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "53436036",
      "metadata": {
        "id": "53436036"
      },
      "outputs": [],
      "source": [
        "def client_fn(cid: str) -> FlowerClient: # this is a factory function (factory desing pattern)\n",
        "    net = LeNet5(10).to(DEVICE) # flower calls this function to create FlowerClients on demand (this way it uses less memory)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "\n",
        "    if int(cid) <= NUM_CLIENTS * 0.2:    # 20 - 80 --> malicious - benign\n",
        "        return MaliciousFlowerClient(net, trainloader, valloader, eps=200.0, nm=0.3, mgn=1.0, history = histories[int(cid)], cid=int(cid))\n",
        "    else:\n",
        "        return BenignFlowerClient(net, trainloader, valloader, eps=200.0, nm=0.3, mgn=1.0, history = histories[int(cid)], cid=int(cid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "70f89874",
      "metadata": {
        "id": "70f89874"
      },
      "outputs": [],
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics: # we pass this function as an argument to the Strategy\n",
        "    # calculate accuracy\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # return it as a dictionary\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "HWCt6JB-um6W",
      "metadata": {
        "id": "HWCt6JB-um6W"
      },
      "outputs": [],
      "source": [
        "federatedModel = LeNet5(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "0a7aa153",
      "metadata": {
        "id": "0a7aa153"
      },
      "outputs": [],
      "source": [
        "class AttackSimulationStrategy(fl.server.strategy.FedAvg): # we inherit from FedAvg strategy and change only what we need\n",
        "    def __init__(self, *, fraction_fit: float = 1.0, fraction_evaluate: float = 1.0, min_fit_clients: int = 2,\n",
        "        min_evaluate_clients: int = 2, min_available_clients: int = 2, num_malicious_clients: int = 2,\n",
        "        num_clients_to_keep: int = 0, evaluate_fn: Optional[Callable[[int, NDArrays, Dict[str, Scalar]],\n",
        "        Optional[Tuple[float, Dict[str, Scalar]]],]] = None, on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None, accept_failures: bool = True,\n",
        "        initial_parameters: Optional[Parameters] = None, fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        perturbationVector: str, adversaryKnowledge: str\n",
        "    ) -> None:\n",
        "        super().__init__(\n",
        "            fraction_fit=fraction_fit, fraction_evaluate=fraction_evaluate, min_fit_clients=min_fit_clients,\n",
        "            min_evaluate_clients=min_evaluate_clients, min_available_clients=min_available_clients, evaluate_fn=evaluate_fn,\n",
        "            on_fit_config_fn=on_fit_config_fn, on_evaluate_config_fn=on_evaluate_config_fn, accept_failures=accept_failures,\n",
        "            initial_parameters=initial_parameters, fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n",
        "            evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n",
        "        )\n",
        "        self.num_malicious_clients = num_malicious_clients\n",
        "        self.num_clients_to_keep = num_clients_to_keep\n",
        "        self.perturbationVector = perturbationVector\n",
        "        self.adversaryKnowledge = adversaryKnowledge\n",
        "        self.max_epsilon = 0.0 # this is the global privacy budget\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        rep = f\"AttackSimulationStrategy(accept_failures={self.accept_failures})\"\n",
        "        return rep\n",
        "\n",
        "    def aggregate_fit(self, server_round: int, results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "\n",
        "        if not results: # boilerplate code to handle exceptions\n",
        "            return None, {}\n",
        "        if not self.accept_failures and failures:\n",
        "            return None, {}\n",
        "\n",
        "        accepted_results = [] # get the privacy budget of each client\n",
        "        disconnect_clients = []\n",
        "        epsilons = []\n",
        "        i = 0\n",
        "        for c, r in results:\n",
        "            histories[i] = r.metrics[\"history\"]\n",
        "            if r.metrics[\"accept\"]:\n",
        "                accepted_results.append([c, r])\n",
        "                epsilons.append(r.metrics[\"epsilon\"])\n",
        "            else:\n",
        "                disconnect_clients.append(c)\n",
        "            i = i + 1\n",
        "\n",
        "        for c in disconnect_clients:\n",
        "            c.reconnect(ReconnectIns(seconds=None), timeout=None)\n",
        "\n",
        "        results = accepted_results\n",
        "        if epsilons:\n",
        "            self.max_epsilon = max(self.max_epsilon, max(epsilons))\n",
        "        print(f\"Privacy budget ε at round {server_round}: {self.max_epsilon}\")\n",
        "\n",
        "        # convert results\n",
        "        total_weights_results = [(parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples) for _, fit_res in results]\n",
        "\n",
        "        # calculate Non Attack AGR\n",
        "        parameters_aggregated = ndarrays_to_parameters(aggregate(total_weights_results))\n",
        "\n",
        "        # update federated learning model\n",
        "        set_parameters(federatedModel, parameters_to_ndarrays(parameters_aggregated))\n",
        "\n",
        "        # boilerplate code if aggregation metrics are provided\n",
        "        metrics_aggregated = {}\n",
        "        if self.fit_metrics_aggregation_fn:\n",
        "            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
        "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
        "        elif server_round == 1:  # Only log this warning once\n",
        "            log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
        "\n",
        "        return parameters_aggregated, metrics_aggregated\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "1befdde0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1befdde0",
        "outputId": "774a2747-a64a-45fb-9de4-beec1ffedd4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2023-11-12 17:43:33,376 | app.py:175 | Starting Flower simulation, config: ServerConfig(num_rounds=11, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=11, round_timeout=None)\n",
            "2023-11-12 17:43:35,827\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2023-11-12 17:43:37,631 | app.py:210 | Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'memory': 7842678375.0, 'object_store_memory': 3921339187.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'memory': 7842678375.0, 'object_store_memory': 3921339187.0}\n",
            "INFO flwr 2023-11-12 17:43:37,637 | app.py:218 | No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO flwr 2023-11-12 17:43:37,643 | app.py:224 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO flwr 2023-11-12 17:43:37,672 | app.py:270 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO flwr 2023-11-12 17:43:37,680 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-11-12 17:43:37,686 | server.py:276 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=2126)\u001b[0m 2023-11-12 17:43:40.163651: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2126)\u001b[0m 2023-11-12 17:43:40.163732: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2126)\u001b[0m 2023-11-12 17:43:40.163765: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2126)\u001b[0m 2023-11-12 17:43:41.724317: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO flwr 2023-11-12 17:43:47,669 | server.py:280 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-11-12 17:43:47,675 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-11-12 17:43:47,680 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-11-12 17:43:47,681 | server.py:222 | fit_round 1: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 4 clients (out of 4)\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2126)\u001b[0m /usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2126)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(pid=2125)\u001b[0m 2023-11-12 17:43:40.340294: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2125)\u001b[0m 2023-11-12 17:43:40.340342: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2125)\u001b[0m 2023-11-12 17:43:40.340371: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2125)\u001b[0m 2023-11-12 17:43:41.839710: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2126)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2126)\u001b[0m   warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2126)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1349: UserWarning: Using a non-full backward hook when outputs are generated by different autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2126)\u001b[0m   warnings.warn(\"Using a non-full backward hook when outputs are generated by different autograd Nodes \"\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2126)\u001b[0m /usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2126)\u001b[0m   z = np.log((np.exp(t) + q - 1) / q)\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2125)\u001b[0m /usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2125)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2125)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2125)\u001b[0m   warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2125)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1349: UserWarning: Using a non-full backward hook when outputs are generated by different autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2125)\u001b[0m   warnings.warn(\"Using a non-full backward hook when outputs are generated by different autograd Nodes \"\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2125)\u001b[0m /usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2125)\u001b[0m   z = np.log((np.exp(t) + q - 1) / q)\n",
            "DEBUG flwr 2023-11-12 17:44:40,418 | server.py:236 | fit_round 1 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 4 results and 0 failures\n",
            "WARNING flwr 2023-11-12 17:44:40,439 | <ipython-input-24-4a675eae5921>:72 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-11-12 17:44:40,443 | server.py:173 | evaluate_round 1: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Privacy budget ε at round 1: 20.690627889756946\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-11-12 17:44:45,460 | server.py:187 | evaluate_round 1 received 4 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:44:45,466 | server.py:222 | fit_round 2: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-11-12 17:45:34,286 | server.py:236 | fit_round 2 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:45:34,304 | server.py:173 | evaluate_round 2: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Privacy budget ε at round 2: 26.710303858014665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-11-12 17:45:40,417 | server.py:187 | evaluate_round 2 received 4 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:45:40,421 | server.py:222 | fit_round 3: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-11-12 17:46:35,037 | server.py:236 | fit_round 3 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:46:35,063 | server.py:173 | evaluate_round 3: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Privacy budget ε at round 3: 31.572781544878836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-11-12 17:46:40,550 | server.py:187 | evaluate_round 3 received 4 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:46:40,553 | server.py:222 | fit_round 4: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-11-12 17:47:29,984 | server.py:236 | fit_round 4 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:47:30,002 | server.py:173 | evaluate_round 4: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Privacy budget ε at round 4: 35.85593406877192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-11-12 17:47:37,038 | server.py:187 | evaluate_round 4 received 4 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:47:37,041 | server.py:222 | fit_round 5: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-11-12 17:48:29,806 | server.py:236 | fit_round 5 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:48:29,825 | server.py:173 | evaluate_round 5: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Privacy budget ε at round 5: 39.776106375073866\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-11-12 17:48:35,039 | server.py:187 | evaluate_round 5 received 4 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:48:35,042 | server.py:222 | fit_round 6: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 6: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-11-12 17:49:25,174 | server.py:236 | fit_round 6 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 6 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:49:25,193 | server.py:173 | evaluate_round 6: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 6: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Privacy budget ε at round 6: 43.44133970609111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-11-12 17:49:32,822 | server.py:187 | evaluate_round 6 received 4 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 6 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:49:32,827 | server.py:222 | fit_round 7: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 7: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-11-12 17:50:26,091 | server.py:236 | fit_round 7 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 7 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:50:26,109 | server.py:173 | evaluate_round 7: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 7: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Privacy budget ε at round 7: 46.915331621582204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-11-12 17:50:31,195 | server.py:187 | evaluate_round 7 received 4 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 7 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:50:31,201 | server.py:222 | fit_round 8: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 8: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-11-12 17:51:21,498 | server.py:236 | fit_round 8 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 8 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:51:21,529 | server.py:173 | evaluate_round 8: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 8: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Privacy budget ε at round 8: 50.23897734733542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-11-12 17:51:29,302 | server.py:187 | evaluate_round 8 received 4 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 8 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:51:29,307 | server.py:222 | fit_round 9: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 9: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-11-12 17:52:20,608 | server.py:236 | fit_round 9 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 9 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:52:20,628 | server.py:173 | evaluate_round 9: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 9: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Privacy budget ε at round 9: 53.440010087080424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-11-12 17:52:25,823 | server.py:187 | evaluate_round 9 received 4 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 9 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:52:25,825 | server.py:222 | fit_round 10: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 10: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-11-12 17:53:19,322 | server.py:236 | fit_round 10 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 10 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:53:19,356 | server.py:173 | evaluate_round 10: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 10: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Privacy budget ε at round 10: 56.53929360975448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-11-12 17:53:24,968 | server.py:187 | evaluate_round 10 received 4 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 10 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:53:24,971 | server.py:222 | fit_round 11: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 11: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-11-12 17:54:18,733 | server.py:236 | fit_round 11 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 11 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-11-12 17:54:18,754 | server.py:173 | evaluate_round 11: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 11: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Privacy budget ε at round 11: 59.551722659010956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-11-12 17:54:26,483 | server.py:187 | evaluate_round 11 received 4 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 11 received 4 results and 0 failures\n",
            "INFO flwr 2023-11-12 17:54:26,486 | server.py:153 | FL finished in 638.80449234\n",
            "INFO:flwr:FL finished in 638.80449234\n",
            "INFO flwr 2023-11-12 17:54:26,490 | app.py:225 | app_fit: losses_distributed [(1, 0.06547332084178924), (2, 0.06317389583587647), (3, 0.062029316961765286), (4, 0.06050258672237396), (5, 0.058819595575332645), (6, 0.05797963374853134), (7, 0.057408484101295475), (8, 0.056748649239540094), (9, 0.05643638944625855), (10, 0.056866947054862976), (11, 0.05624494415521622)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.06547332084178924), (2, 0.06317389583587647), (3, 0.062029316961765286), (4, 0.06050258672237396), (5, 0.058819595575332645), (6, 0.05797963374853134), (7, 0.057408484101295475), (8, 0.056748649239540094), (9, 0.05643638944625855), (10, 0.056866947054862976), (11, 0.05624494415521622)]\n",
            "INFO flwr 2023-11-12 17:54:26,493 | app.py:226 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-11-12 17:54:26,495 | app.py:227 | app_fit: metrics_distributed {'accuracy': [(1, 0.2855), (2, 0.3), (3, 0.3095), (4, 0.33799999999999997), (5, 0.35250000000000004), (6, 0.359), (7, 0.36650000000000005), (8, 0.37850000000000006), (9, 0.38049999999999995), (10, 0.38850000000000007), (11, 0.38850000000000007)]}\n",
            "INFO:flwr:app_fit: metrics_distributed {'accuracy': [(1, 0.2855), (2, 0.3), (3, 0.3095), (4, 0.33799999999999997), (5, 0.35250000000000004), (6, 0.359), (7, 0.36650000000000005), (8, 0.37850000000000006), (9, 0.38049999999999995), (10, 0.38850000000000007), (11, 0.38850000000000007)]}\n",
            "INFO flwr 2023-11-12 17:54:26,496 | app.py:228 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-11-12 17:54:26,498 | app.py:229 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.06547332084178924\n",
              "\tround 2: 0.06317389583587647\n",
              "\tround 3: 0.062029316961765286\n",
              "\tround 4: 0.06050258672237396\n",
              "\tround 5: 0.058819595575332645\n",
              "\tround 6: 0.05797963374853134\n",
              "\tround 7: 0.057408484101295475\n",
              "\tround 8: 0.056748649239540094\n",
              "\tround 9: 0.05643638944625855\n",
              "\tround 10: 0.056866947054862976\n",
              "\tround 11: 0.05624494415521622\n",
              "History (metrics, distributed, evaluate):\n",
              "{'accuracy': [(1, 0.2855), (2, 0.3), (3, 0.3095), (4, 0.33799999999999997), (5, 0.35250000000000004), (6, 0.359), (7, 0.36650000000000005), (8, 0.37850000000000006), (9, 0.38049999999999995), (10, 0.38850000000000007), (11, 0.38850000000000007)]}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a strategy\n",
        "strategy = AttackSimulationStrategy(fraction_fit=1.0, fraction_evaluate=0.75, min_fit_clients=4,\n",
        "    min_evaluate_clients=4, min_available_clients=4, perturbationVector=\"InverseStd\", adversaryKnowledge=\"agr-only\",\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,) # <-- pass the metric aggregation function. This function will be called\n",
        "                                                       # in every federated learning round for evaluation (it aggregates the\n",
        "                                                       # client-side evaluation metrics in the server)\n",
        "\n",
        "# start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn, # out factory function\n",
        "    num_clients=4, # number of clients\n",
        "    config=fl.server.ServerConfig(num_rounds=11), # number of federated learning rounds\n",
        "    strategy=strategy, # our attack simulation strategy\n",
        "    client_resources=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "ENAkqHxkv-kT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENAkqHxkv-kT",
        "outputId": "969f505c-93b2-4fa7-af74-5ef83b19319b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.05311087976694107, 0.4123)\n"
          ]
        }
      ],
      "source": [
        "print(test(federatedModel, testloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "kyAcZl6u3HkJ",
      "metadata": {
        "id": "kyAcZl6u3HkJ"
      },
      "outputs": [],
      "source": [
        "class AttackDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.data = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def __insertitem___(self, item):\n",
        "        self.data.append(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "Lc8HRgk7uKt9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc8HRgk7uKt9",
        "outputId": "8816b5fa-26dd-4913-d737-46bc6056eff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0\n",
            "0 1\n",
            "0 2\n",
            "0 3\n",
            "0 4\n",
            "0 5\n",
            "0 6\n",
            "0 7\n",
            "0 8\n",
            "0 9\n",
            "0 10\n",
            "1 0\n",
            "1 1\n",
            "1 2\n",
            "1 3\n",
            "1 4\n",
            "1 5\n",
            "1 6\n",
            "1 7\n",
            "1 8\n",
            "1 9\n",
            "1 10\n",
            "2 0\n",
            "2 1\n",
            "2 2\n",
            "2 3\n",
            "2 4\n",
            "2 5\n",
            "2 6\n",
            "2 7\n",
            "2 8\n",
            "2 9\n",
            "2 10\n"
          ]
        }
      ],
      "source": [
        "### Membership Inference Attack###\n",
        "\n",
        "# create and train shadow models\n",
        "shadowModelsTotal = 3\n",
        "shift = 4\n",
        "\n",
        "shadowModels = [LeNet5(10) for _ in range(shadowModelsTotal)]\n",
        "for idx in range(shadowModelsTotal):\n",
        "    for epochidx in range(11):\n",
        "        # print(idx, epochidx)\n",
        "        trainV2(shadowModels[idx], trainloaders[shift+idx], epochs=1)\n",
        "        trainV2(shadowModels[idx], trainloaders[shift+idx+1], epochs=1)\n",
        "        trainV2(shadowModels[idx], trainloaders[shift+idx+2], epochs=1)\n",
        "        trainV2(shadowModels[idx], trainloaders[shift+idx+3], epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "cVOcCMNge8mi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVOcCMNge8mi",
        "outputId": "5a2c7d9c-febe-4902-e043-3bf8fe24fd1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.05718909372091293, 0.5983)\n",
            "(0.06277830110788345, 0.5806)\n",
            "(0.06247637983560562, 0.5828)\n"
          ]
        }
      ],
      "source": [
        "for idx in range(shadowModelsTotal):\n",
        "    print(test(shadowModels[idx], testloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "x-hUuvKa-NUz",
      "metadata": {
        "id": "x-hUuvKa-NUz"
      },
      "outputs": [],
      "source": [
        "# construct attack model's training set\n",
        "import random\n",
        "\n",
        "attackTrainingSet = AttackDataset()\n",
        "for idx in range(shadowModelsTotal):\n",
        "  for images, labels in trainloaders[4+idx]:\n",
        "    logits, probas = shadowModels[idx](images)\n",
        "    for dataidx in range(labels.size()[0]):\n",
        "      attackTrainingSet.__insertitem___((torch.cat((probas[dataidx], torch.as_tensor([labels[dataidx]]))).detach(), 1)) # 1 is in\n",
        "  for images, labels in trainloaders[idx]:\n",
        "    logits, probas = shadowModels[idx](images)\n",
        "    for dataidx in range(labels.size()[0]):\n",
        "      attackTrainingSet.__insertitem___((torch.cat((probas[dataidx], torch.as_tensor([labels[dataidx]]))).detach(), 0)) # 0 is out\n",
        "random.shuffle(attackTrainingSet.data)\n",
        "\n",
        "ds_train = Subset(attackTrainingSet, [i for i in range(attackTrainingSet.__len__())])\n",
        "attackSet = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "VzWoZYJZwSAB",
      "metadata": {
        "id": "VzWoZYJZwSAB"
      },
      "outputs": [],
      "source": [
        "# create and train the attack model\n",
        "attackModel = AttackMLP(11)\n",
        "trainV2(attackModel, attackSet, epochs=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "ktxF9P678Ipe",
      "metadata": {
        "id": "ktxF9P678Ipe"
      },
      "outputs": [],
      "source": [
        "# construct attack model's evaluation set\n",
        "attackEvaluationSet = AttackDataset()\n",
        "for idx in range(1):\n",
        "  for images, labels in testloader:\n",
        "    logits, probas = federatedModel(images)\n",
        "    for dataidx in range(labels.size()[0]):\n",
        "      attackEvaluationSet.__insertitem___((torch.cat((probas[dataidx], torch.as_tensor([labels[dataidx]]))), 0)) # 1 is in - 0 is out\n",
        "for idx in range(1):\n",
        "  for images, labels in trainloaders[idx]:\n",
        "    logits, probas = federatedModel(images)\n",
        "    for dataidx in range(labels.size()[0]):\n",
        "      attackEvaluationSet.__insertitem___((torch.cat((probas[dataidx], torch.as_tensor([labels[dataidx]]))), 1)) # 1 is in - 0 is out\n",
        "\n",
        "ds_eval = Subset(attackEvaluationSet, [i for i in range(attackEvaluationSet.__len__())])\n",
        "attackEvalSet = DataLoader(ds_eval, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "KR5j4S0m7bZI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR5j4S0m7bZI",
        "outputId": "11d9ec9a-6706-4d25-9215-6deee0854430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.663448275862069\n",
            "class: 0 = 0.6187245590230664\n",
            "class: 1 = 0.6936936936936937\n",
            "class: 2 = 0.700770847932726\n",
            "class: 3 = 0.7087172218284904\n",
            "class: 4 = 0.6925207756232687\n",
            "class: 5 = 0.6717346233586731\n",
            "class: 6 = 0.6271186440677966\n",
            "class: 7 = 0.6612133605998637\n",
            "class: 8 = 0.6172248803827751\n",
            "class: 9 = 0.6466528640441684\n"
          ]
        }
      ],
      "source": [
        "# evaluation\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "loss = 0.0\n",
        "correct = [0 for _ in range(10)]\n",
        "total = [0 for _ in range(10)]\n",
        "attackModel.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in attackEvalSet:\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        outputs, probas = attackModel(images)\n",
        "        loss += criterion(outputs, labels).item()\n",
        "        _, predicted = torch.max(probas.data, 1)\n",
        "        total[int(images[0][10].item())] += labels.size(0)\n",
        "        correct[int(images[0][10].item())] += (predicted == labels).sum().item()\n",
        "loss /= len(attackEvalSet.dataset)\n",
        "print(sum(correct) / sum(total))\n",
        "for i in range(10):\n",
        "  print(\"class:\", i, \"=\", correct[i]/total[i])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
