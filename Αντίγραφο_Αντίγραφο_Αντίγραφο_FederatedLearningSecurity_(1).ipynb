{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a084d0fc"
      },
      "source": [
        "# Federated Learning Model Poisoning Attack Simulation"
      ],
      "id": "a084d0fc"
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "c41d4476"
      },
      "outputs": [],
      "source": [
        "!pip install -q flwr[simulation] torch torchvision matplotlib opacus\n",
        "\n",
        "from collections import OrderedDict\n",
        "from typing import List, Tuple, Optional, Callable, Dict\n",
        "from matplotlib import pyplot as plt\n",
        "import certifi\n",
        "import ssl\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "from torchvision.datasets import CIFAR10\n",
        "import flwr as fl\n",
        "from flwr.common import Parameters, Scalar, FitRes, Metrics\n",
        "import os\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.utils.uniform_sampler import UniformWithReplacementSampler\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" # fixed something with matplotlib killing the kernel\n",
        "ssl._create_default_https_context = ssl._create_unverified_context  # fixed something with the ssl certificate of the dataset\n",
        "DEVICE = torch.device(\"cpu\")  # \"cpu\" -> train in cpu | \"cuda\" -> train in gpu"
      ],
      "id": "c41d4476"
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "225fa440"
      },
      "outputs": [],
      "source": [
        "from logging import WARNING # we need those imports to implement the strategy class\n",
        "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "from flwr.common import (\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    MetricsAggregationFn,\n",
        "    NDArrays,\n",
        "    Parameters,\n",
        "    Scalar,\n",
        "    ndarrays_to_parameters,\n",
        "    parameters_to_ndarrays,\n",
        ")\n",
        "from flwr.common.logger import log\n",
        "from flwr.server.client_manager import ClientManager\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "\n",
        "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg, aggregate_krum\n",
        "from flwr.server.strategy.strategy import Strategy"
      ],
      "id": "225fa440"
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "e7a839c4"
      },
      "outputs": [],
      "source": [
        "CLASSES = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\") # classes of the example dataset\n",
        "\n",
        "NUM_CLIENTS = 10 # this is the number of devices participating in the federated learning\n",
        "\n",
        "BATCH_SIZE = 32 # this is the size of a mini-batch for the training of a CNN using SGD"
      ],
      "id": "e7a839c4"
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe1dcda9",
        "outputId": "72fd4e81-425a-4698-cd0e-c4b206c58420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "def load_datasets(): # download and transform cifar-10\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
        "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
        "\n",
        "    # split training set into 10 partitions to simulate the individual dataset\n",
        "    partition_size = len(trainset) // NUM_CLIENTS\n",
        "    lengths = [partition_size] * NUM_CLIENTS\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10% validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets() # load the datasets"
      ],
      "id": "fe1dcda9"
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "876b7b4b"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module): # here we create a neural network class that inherits from nn.Module\n",
        "    def __init__(self) -> None: # we have to implement only two functions, the constructor and the forward pass\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "id": "876b7b4b"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_target_delta(data_size: int) -> float: # this is the δ for the (ε, δ) differential privacy\n",
        "    den = 1\n",
        "    while data_size // den >= 1:\n",
        "        den *= 10\n",
        "    return 1 / den"
      ],
      "metadata": {
        "id": "TeE3kaOQYL8T"
      },
      "id": "TeE3kaOQYL8T",
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "2d8d6556"
      },
      "outputs": [],
      "source": [
        "def train(net, trainloader, epochs: int, nm, mgn, eps, vbatch_size, state_dict, verbose=False): # we need a train and a test function that our clients will be using\n",
        "    # assert(vbatch_size%BATCH_SIZE==0)\n",
        "    n_acc_steps = int(vbatch_size / BATCH_SIZE)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    alphas = [1 + x / 10.0 for x in range(1, 100)] + list(range(12, 64)) # rdp orders\n",
        "    delta = get_target_delta(len(trainloader.dataset)) # dp δ\n",
        "    sample_rate = BATCH_SIZE / len(trainloader.dataset)\n",
        "\n",
        "    privacy_engine = PrivacyEngine()\n",
        "    net, optimizer, trainloader = privacy_engine.make_private(\n",
        "        module=net,\n",
        "        optimizer=optimizer, # here we attach the optimizer with the DP engine so that in every stochastic gradient descent step it adds noise + gradient clipping + etc!\n",
        "        data_loader=trainloader,\n",
        "        noise_multiplier=nm,\n",
        "        max_grad_norm=mgn,\n",
        "    )\n",
        "\n",
        "    if state_dict is not None:\n",
        "      privacy_engine.load_state_dict(state_dict)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        correct, total, epoch_loss, ctr = 0, 0, 0.0, 0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images) # do the forward pass\n",
        "            loss = criterion(outputs, labels) # calculate the loss function\n",
        "            loss.backward() # calculate the gradients of the loss function\n",
        "\n",
        "\n",
        "            optimizer.step()  # the optimizer is now a dp-optimizer and this will be a real step or a virtual step depending on the dp state!\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "            ctr = ctr + 1\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "\n",
        "        if verbose: # log information\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "id": "2d8d6556"
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "88a324a2"
      },
      "outputs": [],
      "source": [
        "def get_parameters(net) -> List[np.ndarray]: # we need these two function because this way flower knows how\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()] # to serialize/deserialize data\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)"
      ],
      "id": "88a324a2"
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "9a3bd9fc"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient): # here we define the FlowerClient. We have to implement only the following 3 methods\n",
        "    def __init__(self, net, trainloader, valloader): # of course we can customize these methods as we like\n",
        "        self.net = net                            # we can add extra member variables as well\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1, mgn=1.0, nm=1.2, eps=0.0, vbatch_size=128, state_dict= None)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
      ],
      "id": "9a3bd9fc"
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "0acd8c0d"
      },
      "outputs": [],
      "source": [
        "class BenignFlowerClient(FlowerClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        super().__init__(net, trainloader, valloader)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        #print(\"Benign Client Got Selected\", flush=True)\n",
        "        parameters, num_examples, _ = super().fit(parameters, config)\n",
        "        return parameters, num_examples, {\"intention\": \"BENIGN\"}\n",
        "\n",
        "class MaliciousFlowerClient(FlowerClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        super().__init__(net, trainloader, valloader)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        #print(\"Malicious Client Got Selected\", flush=True)\n",
        "        parameters, num_examples, _ = super().fit(parameters, config)\n",
        "        return parameters, num_examples, {\"intention\": \"MALICIOUS\"}"
      ],
      "id": "0acd8c0d"
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "53436036"
      },
      "outputs": [],
      "source": [
        "def client_fn(cid: str) -> FlowerClient: # this is a factory function (factory desing pattern)\n",
        "    net = Net().to(DEVICE) # flower calls this function to create FlowerClients on demand (this way it uses less memory)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "\n",
        "    if int(cid) <= NUM_CLIENTS * 0.2:    # 20 - 80 --> malicious - benign\n",
        "        return MaliciousFlowerClient(net, trainloader, valloader)\n",
        "    else:\n",
        "        return BenignFlowerClient(net, trainloader, valloader)"
      ],
      "id": "53436036"
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "70f89874"
      },
      "outputs": [],
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics: # we pass this function as an argument to the Strategy\n",
        "    # calculate accuracy\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # return it as a dictionary\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "id": "70f89874"
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "0a7aa153"
      },
      "outputs": [],
      "source": [
        "class AttackSimulationStrategy(fl.server.strategy.FedAvg): # we inherit from FedAvg strategy and change only what we need\n",
        "    def __init__(self, *, fraction_fit: float = 1.0, fraction_evaluate: float = 1.0, min_fit_clients: int = 2,\n",
        "        min_evaluate_clients: int = 2, min_available_clients: int = 2, num_malicious_clients: int = 2,\n",
        "        num_clients_to_keep: int = 0, evaluate_fn: Optional[Callable[[int, NDArrays, Dict[str, Scalar]],\n",
        "        Optional[Tuple[float, Dict[str, Scalar]]],]] = None, on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None, accept_failures: bool = True,\n",
        "        initial_parameters: Optional[Parameters] = None, fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        perturbationVector: str, adversaryKnowledge: str\n",
        "    ) -> None:\n",
        "        super().__init__(\n",
        "            fraction_fit=fraction_fit, fraction_evaluate=fraction_evaluate, min_fit_clients=min_fit_clients,\n",
        "            min_evaluate_clients=min_evaluate_clients, min_available_clients=min_available_clients, evaluate_fn=evaluate_fn,\n",
        "            on_fit_config_fn=on_fit_config_fn, on_evaluate_config_fn=on_evaluate_config_fn, accept_failures=accept_failures,\n",
        "            initial_parameters=initial_parameters, fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n",
        "            evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n",
        "        )\n",
        "        self.num_malicious_clients = num_malicious_clients\n",
        "        self.num_clients_to_keep = num_clients_to_keep\n",
        "        self.perturbationVector = perturbationVector\n",
        "        self.adversaryKnowledge = adversaryKnowledge\n",
        "        self.max_epsilon = 0.0 # this is the global privacy budget\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        rep = f\"AttackSimulationStrategy(accept_failures={self.accept_failures})\"\n",
        "        return rep\n",
        "\n",
        "    def aggregate_fit(self, server_round: int, results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "\n",
        "        if not results: # boilerplate code to handle exceptions\n",
        "            return None, {}\n",
        "        if not self.accept_failures and failures:\n",
        "            return None, {}\n",
        "\n",
        "\n",
        "        accepted_results = [] # get the privacy budget of each client\n",
        "        disconnect_clients = []\n",
        "        epsilons = []\n",
        "        for c, r in results:\n",
        "            if r.metrics[\"accept\"]:\n",
        "                accepted_results.append([c, r])\n",
        "                epsilons.append(r.metrics[\"epsilon\"])\n",
        "            else:\n",
        "                disconnect_clients.append(c)\n",
        "\n",
        "        #if disconnect_clients: # disconnect clients if needed\n",
        "            #shutdown(disconnect_clients)\n",
        "        results = accepted_results\n",
        "        if epsilons:\n",
        "            self.max_epsilon = max(self.max_epsilon, max(epsilons))\n",
        "        print(f\"Privacy budget ε at round {server_round}: {self.max_epsilon}\")\n",
        "        # Call aggregate_evaluate from base class (FedAvg)\n",
        "        return super().aggregate_fit(server_round, results, failures)\n",
        "\n",
        "        # convert results\n",
        "        total_weights_results = [(parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples) for _, fit_res in results]\n",
        "\n",
        "        \"\"\"\n",
        "        #############################################################################\n",
        "        #########################----SIMULATE THE ATTACK----#########################\n",
        "        #############################################################################\n",
        "        benign_weights_results = [(parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples) for _, fit_res in results\n",
        "                         if fit_res.metrics[\"intention\"] == \"BENIGN\"]\n",
        "        if self.adversaryKnowledge == \"agr-only\" or self.adversaryKnowledge == \"agnostic\":\n",
        "            malicious_weights_results = [(parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples) for _, fit_res in results\n",
        "                                if fit_res.metrics[\"intention\"] == \"MALICIOUS\"]\n",
        "            best_parameters = aggregate(total_weights_results) # malicious_weights_results\n",
        "        else:\n",
        "            best_parameters = aggregate(total_weights_results)\n",
        "\n",
        "        # so far we have [1]: all clients parameters, [2]: benign clients parameters (seperate),\n",
        "        #                [3]: malicious clients parameters (seperate), [4]: best_parameters (based on the adversary's knowledge)\n",
        "        # no we have to optimize the model poisoning attack based on the adversary's knowledge and the perturbation vector\n",
        "\n",
        "        # calculate the perturbation vector\n",
        "        if self.perturbationVector == \"InverseSign\":\n",
        "            perturbationVector = [-np.sign(best_parameter) for best_parameter in best_parameters]\n",
        "        if self.perturbationVector == \"InverseStd\":\n",
        "            parameters = [parameters for parameters, _ in total_weights_results]\n",
        "            perturbationVector = []\n",
        "\n",
        "            for parameterIdx in range(len(parameters[0])):\n",
        "                arr = []\n",
        "                for clientIdx in range(len(parameters)):\n",
        "                    arr.append(parameters[clientIdx][parameterIdx])\n",
        "                numpyArr = np.stack(arr)\n",
        "                perturbationVector.append(-np.std(numpyArr, axis=0))\n",
        "\n",
        "        # optimize for gamma\n",
        "        gamma_init = 100.0\n",
        "        gamma = gamma_init\n",
        "        gamma_succ = 0.0\n",
        "        t = 0.000001 # threshold\n",
        "        step = gamma_init\n",
        "\n",
        "        while True: # this is a c++ do-while loop emulation\n",
        "            malicious_parameters = []\n",
        "            for idx in range(len(perturbationVector)):\n",
        "                malicious_parameters.append(best_parameters[idx] + gamma*perturbationVector[idx])\n",
        "\n",
        "            new_malicious_weights_results = [(malicious_parameters, num_examples) for _, num_examples in malicious_weights_results]\n",
        "            new_total_weights_results = new_malicious_weights_results + benign_weights_results\n",
        "\n",
        "            are_equal = True\n",
        "            krum_parameters = aggregate_krum(new_total_weights_results, self.num_malicious_clients, self.num_clients_to_keep)\n",
        "            for idx in range(len(krum_parameters)):\n",
        "                if np.array_equal(malicious_parameters[idx], krum_parameters[idx]) == False:\n",
        "                    are_equal = False\n",
        "                    break\n",
        "\n",
        "            if are_equal:\n",
        "                gamma_succ = gamma\n",
        "                gamma = gamma + step/2\n",
        "            else:\n",
        "                gamma = gamma - step/2\n",
        "            step = step/2\n",
        "\n",
        "            if abs(gamma_succ - gamma) < t:\n",
        "                break\n",
        "\n",
        "            print(gamma, gamma_succ)\n",
        "\n",
        "        malicious_parameters = []\n",
        "        for idx in range(len(perturbationVector)):\n",
        "            malicious_parameters.append(best_parameters[idx] + gamma_succ*perturbationVector[idx])\n",
        "        new_malicious_weights_results = [(malicious_parameters, num_examples) for _, num_examples in malicious_weights_results]\n",
        "        total_weights_results = new_malicious_weights_results + benign_weights_results\n",
        "        #############################################################################\n",
        "        #############################################################################\n",
        "        #############################################################################\n",
        "        \"\"\"\n",
        "\n",
        "        # calculate AGR\n",
        "        # parameters_aggregated = ndarrays_to_parameters(aggregate_krum( # this thing here is for krum-AGR\n",
        "        #    total_weights_results, self.num_malicious_clients, self.num_clients_to_keep))\n",
        "\n",
        "        # calculate Non Attack AGR\n",
        "        parameters_aggregated = ndarrays_to_parameters(aggregate(total_weights_results))\n",
        "\n",
        "        # boilerplate code if aggregation metrics are provided\n",
        "        metrics_aggregated = {}\n",
        "        if self.fit_metrics_aggregation_fn:\n",
        "            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
        "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
        "        elif server_round == 1:  # Only log this warning once\n",
        "            log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
        "\n",
        "        return parameters_aggregated, metrics_aggregated\n",
        "\n"
      ],
      "id": "0a7aa153"
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "1befdde0",
        "outputId": "c42721d0-e58a-472c-822c-a5ac408d8c56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-09-25 10:08:38,651 | app.py:175 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "2023-09-25 10:08:43,658\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2023-09-25 10:08:47,434 | app.py:210 | Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'object_store_memory': 3939189964.0, 'memory': 7878379931.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'object_store_memory': 3939189964.0, 'memory': 7878379931.0}\n",
            "INFO flwr 2023-09-25 10:08:47,442 | app.py:218 | No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO flwr 2023-09-25 10:08:47,449 | app.py:224 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO flwr 2023-09-25 10:08:47,591 | app.py:270 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO flwr 2023-09-25 10:08:47,600 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-09-25 10:08:47,602 | server.py:276 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=38359)\u001b[0m 2023-09-25 10:09:03.512897: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO flwr 2023-09-25 10:09:09,336 | server.py:280 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-09-25 10:09:09,340 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-09-25 10:09:09,342 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-09-25 10:09:09,347 | server.py:222 | fit_round 1: strategy sampled 8 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 8 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=38360)\u001b[0m /usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=38360)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(pid=38360)\u001b[0m 2023-09-25 10:09:03.549026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=38360)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=38360)\u001b[0m   warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "DEBUG flwr 2023-09-25 10:10:17,528 | server.py:236 | fit_round 1 received 8 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 8 results and 0 failures\n",
            "WARNING flwr 2023-09-25 10:10:17,555 | <ipython-input-149-1c16e9df1df9>:126 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-09-25 10:10:17,559 | server.py:173 | evaluate_round 1: strategy sampled 5 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 5 clients (out of 10)\n",
            "DEBUG flwr 2023-09-25 10:10:28,400 | server.py:187 | evaluate_round 1 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-09-25 10:10:28,408 | server.py:222 | fit_round 2: strategy sampled 8 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 8 clients (out of 10)\n",
            "DEBUG flwr 2023-09-25 10:11:23,923 | server.py:236 | fit_round 2 received 8 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 8 results and 0 failures\n",
            "DEBUG flwr 2023-09-25 10:11:23,948 | server.py:173 | evaluate_round 2: strategy sampled 5 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 5 clients (out of 10)\n",
            "DEBUG flwr 2023-09-25 10:11:32,850 | server.py:187 | evaluate_round 2 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-09-25 10:11:32,854 | server.py:222 | fit_round 3: strategy sampled 8 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 8 clients (out of 10)\n",
            "DEBUG flwr 2023-09-25 10:12:29,304 | server.py:236 | fit_round 3 received 8 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 8 results and 0 failures\n",
            "DEBUG flwr 2023-09-25 10:12:29,329 | server.py:173 | evaluate_round 3: strategy sampled 5 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 5 clients (out of 10)\n",
            "DEBUG flwr 2023-09-25 10:12:37,398 | server.py:187 | evaluate_round 3 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-09-25 10:12:37,404 | server.py:222 | fit_round 4: strategy sampled 8 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 8 clients (out of 10)\n",
            "DEBUG flwr 2023-09-25 10:13:31,930 | server.py:236 | fit_round 4 received 8 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 8 results and 0 failures\n",
            "DEBUG flwr 2023-09-25 10:13:31,974 | server.py:173 | evaluate_round 4: strategy sampled 5 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 5 clients (out of 10)\n",
            "DEBUG flwr 2023-09-25 10:13:42,457 | server.py:187 | evaluate_round 4 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-09-25 10:13:42,460 | server.py:222 | fit_round 5: strategy sampled 8 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 8 clients (out of 10)\n",
            "DEBUG flwr 2023-09-25 10:14:35,757 | server.py:236 | fit_round 5 received 8 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 8 results and 0 failures\n",
            "DEBUG flwr 2023-09-25 10:14:35,785 | server.py:173 | evaluate_round 5: strategy sampled 5 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 5 clients (out of 10)\n",
            "DEBUG flwr 2023-09-25 10:14:46,989 | server.py:187 | evaluate_round 5 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 5 results and 0 failures\n",
            "INFO flwr 2023-09-25 10:14:46,993 | server.py:153 | FL finished in 337.6461198350007\n",
            "INFO:flwr:FL finished in 337.6461198350007\n",
            "INFO flwr 2023-09-25 10:14:46,995 | app.py:225 | app_fit: losses_distributed [(1, 0.07361913843154907), (2, 0.07341510095596314), (3, 0.07257387256622314), (4, 0.07090234088897705), (5, 0.06886343116760255)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.07361913843154907), (2, 0.07341510095596314), (3, 0.07257387256622314), (4, 0.07090234088897705), (5, 0.06886343116760255)]\n",
            "INFO flwr 2023-09-25 10:14:46,998 | app.py:226 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-09-25 10:14:47,000 | app.py:227 | app_fit: metrics_distributed {'accuracy': [(1, 0.11320000000000001), (2, 0.14120000000000002), (3, 0.2008), (4, 0.2052), (5, 0.21200000000000002)]}\n",
            "INFO:flwr:app_fit: metrics_distributed {'accuracy': [(1, 0.11320000000000001), (2, 0.14120000000000002), (3, 0.2008), (4, 0.2052), (5, 0.21200000000000002)]}\n",
            "INFO flwr 2023-09-25 10:14:47,002 | app.py:228 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-09-25 10:14:47,004 | app.py:229 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.07361913843154907\n",
              "\tround 2: 0.07341510095596314\n",
              "\tround 3: 0.07257387256622314\n",
              "\tround 4: 0.07090234088897705\n",
              "\tround 5: 0.06886343116760255\n",
              "History (metrics, distributed, evaluate):\n",
              "{'accuracy': [(1, 0.11320000000000001), (2, 0.14120000000000002), (3, 0.2008), (4, 0.2052), (5, 0.21200000000000002)]}"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "# create a strategy\n",
        "strategy = AttackSimulationStrategy(fraction_fit=0.8, fraction_evaluate=0.5, min_fit_clients=5,\n",
        "    min_evaluate_clients=5, min_available_clients=10, perturbationVector=\"InverseStd\", adversaryKnowledge=\"agr-only\",\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,) # <-- pass the metric aggregation function. This function will be called\n",
        "                                                       # in every federated learning round for evaluation (it aggregates the\n",
        "                                                       # client-side evaluation metrics in the server)\n",
        "\n",
        "# start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn, # out factory function\n",
        "    num_clients=NUM_CLIENTS, # number of clients\n",
        "    config=fl.server.ServerConfig(num_rounds=5), # number of federated learning rounds\n",
        "    strategy=strategy, # our attack simulation strategy\n",
        "    client_resources=None,\n",
        ")"
      ],
      "id": "1befdde0"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}